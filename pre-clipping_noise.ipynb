{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339142d2-15b3-4528-8694-ab504a238f8a",
   "metadata": {},
   "source": [
    "## This exploration tests [functorch](https://pytorch.org/blog/pytorch-1.11-released/)'s per example gradient computation capabilities.\n",
    "\n",
    " We know that clipping gradients in DP-SGD introduces bias. \n",
    " The following code studies the impact of adding symmetric pre-clipping noise on parameter recovery, suggested in Section 5 of [this](https://arxiv.org/pdf/2006.15429.pdf) paper\n",
    " on a toy logistic regression model.\n",
    " To isolate the effect of pre-clipping noise, we don't add DP noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5e7437-f625-44e5-975b-1dd97b244f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-22f7c5159d0193db\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-22f7c5159d0193db\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir runs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7116b3ac-8ba3-4429-ad2e-2f82bed1744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|███████████████████████████████████████████| 20000/20000 [00:25<00:00, 797.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-clipping noise added Parameter containing:\n",
      "tensor([[-0.4662,  2.1820, -6.7592]], requires_grad=True)\n",
      "tensor([-0.1000,  1.0000, -3.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|███████████████████████████████████████████| 20000/20000 [00:27<00:00, 731.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-clipping noise added Parameter containing:\n",
      "tensor([[-0.2526,  1.3531, -4.0759]], requires_grad=True)\n",
      "tensor([-0.1000,  1.0000, -3.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|███████████████████████████████████████████| 20000/20000 [00:28<00:00, 693.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-clipping noise added Parameter containing:\n",
      "tensor([[-0.1051,  1.0689, -3.2646]], requires_grad=True)\n",
      "tensor([-0.1000,  1.0000, -3.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|███████████████████████████████████████████| 20000/20000 [00:28<00:00, 704.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-clipping noise added Parameter containing:\n",
      "tensor([[-0.0916,  1.0892, -3.2130]], requires_grad=True)\n",
      "tensor([-0.1000,  1.0000, -3.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|███████████████████████████████████████████| 20000/20000 [00:28<00:00, 696.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-clipping noise added Parameter containing:\n",
      "tensor([[-0.1472,  1.1842, -3.0960]], requires_grad=True)\n",
      "tensor([-0.1000,  1.0000, -3.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|███████████████████████████████████████████| 20000/20000 [00:30<00:00, 661.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-clipping noise added Parameter containing:\n",
      "tensor([[-0.1372,  0.9170, -2.8401]], requires_grad=True)\n",
      "tensor([-0.1000,  1.0000, -3.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|███████████████████████████████████████████| 20000/20000 [00:31<00:00, 642.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-clipping noise added Parameter containing:\n",
      "tensor([[-0.1209,  0.7847, -2.2054]], requires_grad=True)\n",
      "tensor([-0.1000,  1.0000, -3.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|███████████████████████████████████████████| 20000/20000 [00:31<00:00, 643.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-clipping noise added Parameter containing:\n",
      "tensor([[ 0.2249,  0.1294, -1.3428]], requires_grad=True)\n",
      "tensor([-0.1000,  1.0000, -3.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression as lreg\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functorch import make_functional, vmap, grad\n",
    "from functorch import vmap, grad_and_value\n",
    "from functorch import make_functional\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "default_seed = 1234\n",
    "\n",
    "torch.manual_seed(default_seed)\n",
    "np.random.seed(default_seed)\n",
    "N = 20000\n",
    "\n",
    "\n",
    "shutil.rmtree(\"runs/\",ignore_errors=True) \n",
    "\n",
    "\n",
    "'''\n",
    "True parameter we would like to recover.\n",
    "'''\n",
    "d =3\n",
    "\n",
    "theta = np.array([-0.1,1.0,-3.0])        \n",
    "\n",
    "def create_un_separable_dataset(N,d):\n",
    "    ####\n",
    "    ## Not guaranteed to be linearly seperable.\n",
    "    ###\n",
    "    def sigmoid(x):\n",
    "        return 1.0/(1.0+np.exp(-x))   \n",
    "    \n",
    "    Sigma =datasets.make_spd_matrix(d,random_state = default_seed)\n",
    "    inputs = np.random.multivariate_normal(np.ones(d), Sigma, int(N))\n",
    "    labels = np.random.binomial(1.0, sigmoid(inputs.dot(theta)))\n",
    "    return torch.Tensor(inputs),torch.Tensor(labels)\n",
    "\n",
    "\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim,bias=False) ## Setting model intercept to 0.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "    \n",
    "\n",
    "inputs,labels = create_un_separable_dataset(N,d)\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split( inputs, labels, test_size=0.2, random_state=default_seed)\n",
    "\n",
    "C = 0.1 ## clipping threshold\n",
    "epochs = 20000\n",
    "learning_rate = 0.01\n",
    "N = X_train.shape[0]\n",
    "batch_size = int(np.sqrt(N))\n",
    "theta = torch.tensor(theta)\n",
    "\n",
    "'''\n",
    "The variable k controls the variance of the pre-clipping noise we are adding.\n",
    "'''\n",
    "for k in [0.1,0.5,1.0,2.0,5.0,10.,20.,100.]:\n",
    "    \n",
    "    model_lr  = LogisticRegression(d,1)    \n",
    "    model_init = torch.zeros(d)\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        for param in model_lr.parameters():\n",
    "            param.copy_(model_init)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "    optimizer_batch   = torch.optim.SGD(model_lr.parameters(), lr=learning_rate) \n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    one = torch.ones(1)\n",
    "\n",
    "    def compute_norm_and_clip_grads(grad):\n",
    "        return (grad*torch.minimum(one,C/grad.norm(2,dim=-1)))    \n",
    "   \n",
    "    def get_sample_grads(x,y,model):    \n",
    "        def compute_loss_and_output(weights, x, obesered_y):\n",
    "            predicted_y = func_model(weights, x).squeeze()\n",
    "            loss = criterion(predicted_y, obesered_y)\n",
    "            return loss, predicted_y\n",
    "\n",
    "        func_model, weights = make_functional(model)\n",
    "        grads_loss_output = grad_and_value(compute_loss_and_output, has_aux=True)    \n",
    "        ## using vmap from functorch for fast per example gradient calculations.\n",
    "        sample_grads, (sample_loss, output) = vmap(grads_loss_output, (None, 0, 0))(weights, x, y)   \n",
    "        return sample_grads, (sample_loss, output)\n",
    "\n",
    "    param_list = torch.zeros((epochs,d))\n",
    "    \n",
    "    for epoch in tqdm(range(int(epochs)),desc='Training Epochs'):\n",
    "        optimizer_batch.zero_grad()        \n",
    "\n",
    "        batch_indices=torch.randint(0,N, (batch_size,))\n",
    "        sample_grads, (sample_loss, output)=get_sample_grads(X_train[batch_indices],y_train[batch_indices],model_lr)        \n",
    "        writer.add_scalar(\"training loss:\", sample_loss.mean(), epoch)\n",
    "        for param in model_lr.parameters():\n",
    "            weights = param\n",
    "        \n",
    "        writer.add_scalar(\"distance from true theta:\",torch.linalg.norm(weights- theta,dim=-1),epoch)\n",
    "\n",
    "\n",
    "        sample_grads= sample_grads[0]\n",
    "        \n",
    "        '''\n",
    "        Adding zero mean Gaussian noise to the gradients.\n",
    "        '''\n",
    "        if k >0.0:\n",
    "            sample_grads+= k*torch.randn((batch_size,1,d,))\n",
    "            \n",
    "        '''\n",
    "        Clipping grads with vmap.\n",
    "        '''\n",
    "        clipped_grads = vmap(compute_norm_and_clip_grads)(sample_grads)    \n",
    "\n",
    "        for name, param in model_lr.named_parameters():\n",
    "            param.grad = clipped_grads.sum(0)\n",
    "        optimizer_batch.step()    \n",
    "\n",
    "        \n",
    "    for param in model_lr.parameters():\n",
    "        print(\"pre-clipping noise added\",param)\n",
    "    print(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef39823-6f9d-4650-978b-7a4284f5c9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "225e4195-8e59-46bc-8853-dbaa3a2bd605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5e8e8e3cb7f9774\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5e8e8e3cb7f9774\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir runs/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e6bdac-d0c6-446c-bb8d-9d55a740548c",
   "metadata": {},
   "source": [
    "## In the tensorboard, click on the \"Wall\" axis to compare the training loss and distance of the recovered parameter from the true theta.\n",
    "## We observe that increasing k reduce the training error and improves the accuracy of estimated parameter initially. On the other hand, too large noise scales produce the opposite effect. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
